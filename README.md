# Visual onoma-to-wave
Official implementation of [visual onoma-to-wave]().

## Demo
[[Audio samples]](https://sarulab-speech.github.io/demo_visual-onoma-to-wave/)

The source code and pre-trained model will be available soon.

## Getting started
Codes and pre-trained models will be available soon.

## Code contributors
- Hien Ohnaka (National Institute of Technology, Tokuyama College, Japan.)
- [Shinnosuke Takamichi](https://sites.google.com/site/shinnosuketakamichi/home) (The University of Tokyo, Japan.)

## Reference
- [Onoma-to-wave: Environmental sound synthesis from onomatopoeic words](https://arxiv.org/abs/2102.05872)
- [HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis](https://arxiv.org/abs/2010.05646)
- [FastSpeech2 implementation](https://github.com/Wataru-Nakata/FastSpeech2-JSUT)
  - Part of our codes follows this implementation.